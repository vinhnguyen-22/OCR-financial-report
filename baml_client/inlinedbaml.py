###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> Gemini_2_0_pro {\n  provider google-ai\n  options {\n    model \"gemini-2.0-flash\"\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\nclient<llm> Gemini_1_5_pro {\n  provider google-ai\n  options {\n    model \"gemini-1.5-flash\"\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\nclient<llm> Vertex {\n  provider vertex-ai\n  options {\n    model gemini-1.5-pro\n    location us-central1\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n    temperature 0.2\n  }\n}\n\nclient<llm> CustomOllama {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://Ollama_IP:Ollama_PORT/v1\"\n    model \"llava:7b\"\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.89.0\"\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}",
    "invoice.baml": "class Products{\n    product_name string [] @alias(\"Danh sách tên sản phẩm\") @description(\"List of names of products purchased\")\n    product_quantity string [] @alias(\"Danh sách số lượng sản phẩm\") @description(\"List of quantities of each product purchased\")\n    product_unit_price string [] @alias(\"Danh sách đơn giá tiền sản phẩm\") @description(\"List of unit prices of each product\")\n    product_price string [] @alias(\"Danh sách giá tiền sản phẩm\") @description(\"List of prices of purchased products\")\n}\n\nclass Invoices {\n    datetime string @alias(\"Thời gian mua hàng\") @description(\"Order purchase time. Return format dd/mm/yyyy\")\n    products Products @alias(\"Danh sách sản phẩm\") @description(\"List of products in invoice\")\n    total string @alias(\"Tổng tiền thanh toán\") @description(\"Total amount of purchase invoice payment.\") \n    @@alias(\"Thông tin giấy tờ\") @@description(\"If no information found, leave blank\")\n}\n\n\nfunction ExtractInvoices(images: image[]) -> Invoices {\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client. openai/gpt-4o openai/o1 Gemini_2_0_pro Extract from this content:\n  prompt #\"\n    \n    {{_.role(\"user\")}}\n    Extract information about purchase time and amount paid.\n    {% for img in images %}\n      image-{{loop.index}}:  \n      {{ img }}\n    {% endfor %}\n    {{ ctx.output_format }}\n  \"#\n}",
}

def get_baml_files():
    return file_map